<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]>      <html class="no-js"> <!--<![endif]-->
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Hands Posture Model</title>
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/toastify-js/src/toastify.min.css">
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
    integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
    crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>
    
     <!-- Load TensorFlow.js. This is required to use coco-ssd model. -->


</head>

<body class="bg-light">
  <!--[if lt IE 7]>
      <p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="#">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->
  <div class="container"> 
    <div class="row">

      <div class="row mx-auto my-4">
        <div class="col-9">Hands On Table and Suspicious Object Detection</div>
        <button type="button" class="btn btn-primary col-3" onclick="init()">Start</button>
      </div>
      

      <div class="col-12 my-2" style="width: 100%; text-align: center; margin: 0 auto;">
        <canvas id="canvas" class="d-inline"></canvas>
      </div>
        
      <!-- Pose model results -->
      
    </div>
  </div>


  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
  <!-- Load the coco-ssd model. -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"> </script>
  <script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose

    // the link to your model provided by Teachable Machine export panel
    let model, webcam, ctx, labelContainer, maxPredictions;
    var num = 0;
    var ans = 0;
    var num_2 = 0;
    var ans_2 = 0;
    var hands_tracker = 0;
    async function init() {
    
      model_coco = await cocoSsd.load();
      console.log("loaded coco model");
      const modelURL = "https://teachablemachine.withgoogle.com/models/xNcqCvdFO/" + "model.json";
      const metadataURL = "https://teachablemachine.withgoogle.com/models/xNcqCvdFO/" + "metadata.json";

      // load the model and metadata
      // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
      // Note: the pose library adds a tmPose object to your window (window.tmPose)
      model = await tmPose.load(modelURL, metadataURL);
      maxPredictions = model.getTotalClasses();

      console.log('models_loaded');
      // Convenience function to setup a webcam
      const size = 224;
      const flip = true; // whether to flip the webcam
      webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
      await webcam.setup(); // request access to the webcam
      await webcam.play();
      window.requestAnimationFrame(loop);

      // append/get elements to the DOM
      const canvas = document.getElementById("canvas");
      canvas.width = size; canvas.height = size;
      ctx = canvas.getContext("2d");
      console.log('canvas setup done');
    }

    async function loop(timestamp) {
      webcam.update(); // update the webcam frame
      await predict(model, maxPredictions);
      window.requestAnimationFrame(loop);
    }

    async function predict(model = model, maxPredictions = maxPredictions) {
      // Prediction #1: run input through posenet
      // estimatePose can take in an image, video or canvas html element
      const predictions = await model_coco.detect(canvas);
      //console.log(predictions);
      
      
      let num_people = 0

      predictions.forEach(prediction => {
        let prediction_class = prediction['class']

        if (prediction_class == 'person') {
          num_people++
          if (num_people > 2) {
            // console.log("person")

            Toastify({
              text: "More than 1 person detected!",
              duration: 5000,
              close: true,
              gravity: "top", // `top` or `bottom`
              position: 'right', // `left`, `center` or `right`
              backgroundColor: "#FF0725",
              stopOnFocus: true, // Prevents dismissing of toast on hover
            }).showToast();
            num_people = 0
          }
        }

        if (prediction_class == 'book') {
          Toastify({
            text: "Textbook detected!",
            duration: 5000,
            close: true,
            gravity: "top", // `top` or `bottom`
            position: 'right', // `left`, `center` or `right`
            backgroundColor: "#FF0725",
            stopOnFocus: true, // Prevents dismissing of toast on hover
          }).showToast();
          // console.log("textbook detected")
        }
        if (prediction_class == 'cell phone') {
          Toastify({
            text: "Cell Phone detected!",
            duration: 5000,
            close: true,
            gravity: "top", // `top` or `bottom`
            position: 'right', // `left`, `center` or `right`
            backgroundColor: "#FF0725",
            stopOnFocus: true, // Prevents dismissing of toast on hover
          }).showToast();
        }
      })
      
      const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
      if(pose.keypoints[10].score > 0.5 && pose.keypoints[9].score > 0.5){
		  if(pose.keypoints[10].position.x> 100 && pose.keypoints[9].position.x> 100){
			  console.log("hands on table");
			  hands_tracker += 1;
			  };
			  
		}
      //console.log(pose.keypoints[10].position);
      //const prediction = await model.predict(posenetOutput);

      //let score1 = prediction[0].probability.toFixed(2) * 100
      //let score2 = prediction[1].probability.toFixed(2) * 100
      //document.getElementById("hand1").style.width = `${score1}%`
      //document.getElementById("hand1").innerHTML = `${score1}%`
      //document.getElementById("hand2").style.width = `${score2}%`
      //document.getElementById("hand2").innerHTML = `${score2}%`

      num += 1;
      //ans += parseFloat(prediction[1].probability.toFixed(2));

	  if(num == 10){
      if (hands_tracker/num < 0.1) {
        Toastify({
          text: "Ensure both hands are on the table!",
          duration: 3000,
          close: true,
          gravity: "top", // `top` or `bottom`
          position: 'right', // `left`, `center` or `right`
          backgroundColor: "#FF0725",
          stopOnFocus: true, // Prevents dismissing of toast on hover
        }).showToast();

        // alert("FACE NOT DETECTED!!!");
        ans = 0;
        num = 0;
        hands_tracker = 0;
      } else if (num == 10) {
        ans = 0;
        num = 0;
        hands_tracker = 0;
      }
      
    }
    drawPose(pose);
	}
	
	

    function drawPose(pose) {
      if (webcam.canvas) {
        ctx.drawImage(webcam.canvas, 0, 0);
        // draw the keypoints and skeleton
        if (pose) {
          const minPartConfidence = 0.5;
          tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
          tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
        }
      }
    }
  </script>

  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/toastify-js"></script>

</body>

</html>
